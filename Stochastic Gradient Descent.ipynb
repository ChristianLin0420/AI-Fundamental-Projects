{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Basic Libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load Data\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model Fine Tuning\n",
    "import optuna\n",
    "\n",
    "# Filter Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    def __init__(self, learning_rate=0.01, epochs=100, batch_size=1, reg=None, reg_param=0.0):\n",
    "        \"\"\"\n",
    "        Constructor for the SGDRegressor.\n",
    "\n",
    "        Parameters:\n",
    "        learning_rate (float): The step size used in each update.\n",
    "        epochs (int): Number of passes over the training dataset.\n",
    "        batch_size (int): Number of samples to be used in each batch.\n",
    "        reg (str): Type of regularization ('l1' or 'l2'); None if no regularization.\n",
    "        reg_param (float): Regularization parameter.\n",
    "\n",
    "        The weights and bias are initialized as None and will be set during the fit method.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.reg = reg\n",
    "        self.reg_param = reg_param\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the SGDRegressor to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        X (numpy.ndarray): Training data, shape (m_samples, n_features).\n",
    "        y (numpy.ndarray): Target values, shape (m_samples,).\n",
    "\n",
    "        This method initializes the weights and bias, and then updates them over a number of epochs.\n",
    "        \"\"\"\n",
    "        m, n = X.shape  # m is number of samples, n is number of features\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            indices = np.random.permutation(m)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for i in range(0, m, self.batch_size):\n",
    "                X_batch = X_shuffled[i:i+self.batch_size]\n",
    "                y_batch = y_shuffled[i:i+self.batch_size]\n",
    "\n",
    "                gradient_w = -2 * np.dot(X_batch.T, (y_batch - np.dot(X_batch, self.weights) - self.bias)) / self.batch_size\n",
    "                gradient_b = -2 * np.sum(y_batch - np.dot(X_batch, self.weights) - self.bias) / self.batch_size\n",
    "\n",
    "                if self.reg == 'l1':\n",
    "                    gradient_w += self.reg_param * np.sign(self.weights)\n",
    "                elif self.reg == 'l2':\n",
    "                    gradient_w += self.reg_param * self.weights\n",
    "\n",
    "                self.weights -= self.learning_rate * gradient_w\n",
    "                self.bias -= self.learning_rate * gradient_b\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the target values using the linear model.\n",
    "\n",
    "        Parameters:\n",
    "        X (numpy.ndarray): Data for which to predict target values.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted target values.\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "    def compute_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Computes the loss of the model.\n",
    "\n",
    "        Parameters:\n",
    "        X (numpy.ndarray): The input data.\n",
    "        y (numpy.ndarray): The true target values.\n",
    "\n",
    "        Returns:\n",
    "        float: The computed loss value.\n",
    "        \"\"\"\n",
    "        return (np.mean((y - self.predict(X)) ** 2) + self._get_regularization_loss()) ** 0.5\n",
    "\n",
    "    def _get_regularization_loss(self):\n",
    "        \"\"\"\n",
    "        Computes the regularization loss based on the regularization type.\n",
    "\n",
    "        Returns:\n",
    "        float: The regularization loss.\n",
    "        \"\"\"\n",
    "        if self.reg == 'l1':\n",
    "            return self.reg_param * np.sum(np.abs(self.weights))\n",
    "        elif self.reg == 'l2':\n",
    "            return self.reg_param * np.sum(self.weights ** 2)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Returns the weights of the model.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: The weights of the linear model.\n",
    "        \"\"\"\n",
    "        return self.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
